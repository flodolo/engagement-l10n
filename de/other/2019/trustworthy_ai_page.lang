## NOTE: Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/


# Content of the Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/
;A majority of Mozilla’s movement building work is focused on developing trustworthy AI.
Ein Großteil der Arbeit von Mozilla beim Aufbau von Bewegungen konzentriert sich auf die Entwicklung von vertrauenswürdiger KI.


;We need to move towards a world of AI that is helpful — rather than harmful — to human beings. For us, this means two things: human agency is a core part of how AI is built and integrated and corporate accountability is real and enforced.
Wir müssen uns auf eine Welt der KI zubewegen, die den Menschen eher hilft als schadet. Für uns bedeutet dies zwei Dinge: Die menschliche Entscheidungsfreiheit ist ein zentraler Bestandteil der Art und Weise, wie KI aufgebaut und integriert wird, und die Rechenschaftspflicht des Unternehmens ist real und wird durchgesetzt.


;The need for this work is urgent. Daily, concerning stories hit the news about the effects of AI, big data and targeted marketing; and time and again we read that the public is losing trust in big tech yet doesn’t have any alternatives.
Diese Arbeit ist dringend notwendig. Täglich erscheinen besorgniserregende Nachrichten über die Auswirkungen von KI, Big Data und gezieltem Marketing; und immer wieder lesen wir, dass die Öffentlichkeit das Vertrauen in Big Tech verliert, aber keine Alternativen hat.


;Many of us do not yet fully understand how AI regularly touches our lives and feel powerless in the face of these systems. At Mozilla we’re dedicated to making sure that we all understand that we can and must have a say in when machines are used to make important decisions – and shape how those decisions are made.
Viele von uns verstehen noch nicht ganz, wie KI regelmäßig unser Leben berührt und fühlen sich angesichts dieser Systeme machtlos. Wir bei Mozilla setzen uns dafür ein, dass wir alle verstehen, dass wir mitbestimmen können und müssen, wann Maschinen wichtige Entscheidungen treffen – und Einfluss darauf nehmen, wie diese Entscheidungen getroffen werden.


;The stakes include:
Die wichtigen Punkte sind:


;PRIVACY: Our personal data powers everything from traffic maps to targeted advertising. Trustworthy AI should let people decide how their data is used and what decisions are made with it.
DATENSCHUTZ: Unsere personenbezogenen Daten reichen von Verkehrskarten bis hin zu gezielter Werbung. Vertrauenswürdige KI sollte es den Menschen ermöglichen, zu entscheiden, wie ihre Daten verwendet werden und welche Entscheidungen damit getroffen werden.


;FAIRNESS: We’ve seen time and again that historical bias can show up in automated decision making. To effectively address discrimination, we need to look closely at the goals and data that fuel our AI.
FAIRNESS: Wir haben immer wieder gesehen, dass sich historische Verzerrungen in der automatisierten Entscheidungsfindung zeigen können. Um Diskriminierung wirksam zu bekämpfen, müssen wir uns die Ziele und Daten, die unsere KI befeuern, genau ansehen.


;TRUST: Algorithms on sites like YouTube often push people towards extreme, misleading content. Overhauling these content recommendation systems could go a long way to curbing misinformation.
VERTRAUEN: Algorithmen auf Websites wie YouTube treiben Menschen häufig zu extremen, irreführenden Inhalten. Die Überarbeitung dieser Inhaltsempfehlungssysteme könnte dazu beitragen, Fehlinformationen einzudämmen.


;SAFETY: Experts have raised the alarm that AI could increase security risks and cyber crime. Platform developers will need to create stronger measures to protect our data and personal security.
SICHERHEIT: Experten warnen davor, dass KI Sicherheitsrisiken und Internetkriminalität erhöhen könnte. Plattformentwickler müssen strengere Maßnahmen ergreifen, um unsere Daten und die persönliche Sicherheit zu schützen.


;TRANSPARENCY: Automated decisions can have huge personal impact, yet the reasons for decisions are often opaque. We need breakthroughs in explainability and transparency to protect users.
TRANSPARENZ: Automatisierte Entscheidungen können große persönliche Auswirkungen haben, die Gründe für Entscheidungen sind jedoch oft undurchsichtig. Wir brauchen Durchbrüche in Erklärbarkeit und Transparenz, um die Benutzer zu schützen.


;We are approaching the fight for trustworthy AI in three key ways:
Wir nähern uns dem Kampf um vertrauenswürdige KI auf drei wichtige Arten:


# Alt text
;Systems Change image
Grafik: Systemveränderungen


;We’re shifting the conversation from ‘personal behavior’ to ‘systems change.’
Wir verlagern die Konversation von „persönlichem Verhalten“ auf „Systemveränderung“.


# WOH stands for World Health Organization
;Fellow Renée DiResta has been key in shifting misinfo conversation from ‘fake news’ to ‘<a>free speech does not equal free reach.</a>’ Companies have responded: Pinterest stopped sharing vaccination search results & Facebook has started promoting WHO info with vaccine posts.
Der Stipendiat Renée DiResta hat entscheidend dazu beigetragen, Diskussionen über Falschinformationen von „Fake News“ auf „<a>Redefreiheit bedeutet nicht unbegrenze Reichweite“</a> zu lenken. Unternehmen haben reagiert: Pinterest teilt keine Suchergebnisse zu Impfungen mehr und Facebook wirbt mit Postings zu Impfungen für Informationen der WHO.


# Alt text
;Companies Accountable image
Grafik: Verantwortliche Unternehmen


;We’re holding companies accountable & our approach is spreading.
Wir ziehen Unternehmen zur Verantwortung und unsere Vorgehensweise breitet sich aus.


;For our <a>YouTube Regrets</a> campaign we collected YouTube users’ stories about the platform’s recommendation engine leading them down bizarre and sometimes dangerous pathways. This work was catalyzed by our own research on <a>trustworthy AI</a>; stories in the media; and by YouTube engineers who have <a>spoken out</a>.
Für unsere Kampagne <a>YouTube-Bedauern</a> haben wir YouTube-Nutzerberichte über die Empfehlungs-Engine der Plattform gesammelt, die sie in bizarre und manchmal gefährliche Bahnen gelenkt haben. Diese Arbeit wurde von unserer eigenen Forschung über <a>vertrauenswürdige KI</a> gefördert, Geschichten in den Medien und von YouTube-Ingenieuren, die <a>sich geäußert haben</a>.


# Alt text
;Trustworthy AI innovations image
Grafik: Innovationen zu vertrauenswürdiger KI


;We’re supporting trustworthy AI innovations.
Wir unterstützen Innovationen zu vertrauenswürdiger KI.


;Fellow Dave Gehring’s ‘Meridio Project’ seeks to create a viable economic framework to support journalism outside the current surveillance-based ad model. He’s established the interest and documented the needs among publishers, and will now move to build the platform that would deliver services.
Mit dem „Meridio-Projekt“ des Stipendiaten Dave Gehring soll ein tragfähiger wirtschaftlicher Rahmen geschaffen werden, um den Journalismus außerhalb des aktuellen überwachungsbasierten Anzeigenmodells zu unterstützen. Er hat das Interesse festgestellt und die Bedürfnisse der Verlage dokumentiert und wird nun die Plattform für die Bereitstellung von Diensten aufbauen.


