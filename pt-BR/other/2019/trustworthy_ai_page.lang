## NOTE: Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/


# Content of the Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/
;A majority of Mozilla’s movement building work is focused on developing trustworthy AI.
Maior parte do trabalho de construção em movimento na Mozilla está focada no desenvolvimento de inteligência artificial confiável.


;We need to move towards a world of AI that is helpful — rather than harmful — to human beings. For us, this means two things: human agency is a core part of how AI is built and integrated and corporate accountability is real and enforced.
Precisamos avançar em direção a um mundo em que a inteligência artificial seja útil — ao invés de prejudicial — para os seres humanos. Para nós isso significa duas coisas: a mediação humana seja parte essencial de como a inteligência artificial é criada e integrada, e a responsabilidade corporativa seja real e obrigatória.


;The need for this work is urgent. Daily, concerning stories hit the news about the effects of AI, big data and targeted marketing; and time and again we read that the public is losing trust in big tech yet doesn’t have any alternatives.
A necessidade deste trabalho é urgente. Diariamente, saem nos noticiários histórias preocupantes sobre os efeitos da inteligência artificial, big data e publicidade direcionada. Também, repetidas vezes lemos que o público está perdendo a confiança nas grandes empresas de tecnologia, mas não tem alternativas.


;Many of us do not yet fully understand how AI regularly touches our lives and feel powerless in the face of these systems. At Mozilla we’re dedicated to making sure that we all understand that we can and must have a say in when machines are used to make important decisions – and shape how those decisions are made.
Many of us do not yet fully understand how AI regularly touches our lives and feel powerless in the face of these systems. At Mozilla we’re dedicated to making sure that we all understand that we can and must have a say in when machines are used to make important decisions – and shape how those decisions are made.


;The stakes include:
The stakes include:


;PRIVACY: Our personal data powers everything from traffic maps to targeted advertising. Trustworthy AI should let people decide how their data is used and what decisions are made with it.
PRIVACIDADE: Nossos dados pessoais alimentam tudo, desde mapas de tráfego a publicidade direcionada. A inteligência artificial confiável deve permitir que as pessoas decidam como seus dados são usados e que decisões são tomadas com eles.


;FAIRNESS: We’ve seen time and again that historical bias can show up in automated decision making. To effectively address discrimination, we need to look closely at the goals and data that fuel our AI.
FAIRNESS: We’ve seen time and again that historical bias can show up in automated decision making. To effectively address discrimination, we need to look closely at the goals and data that fuel our AI.


;TRUST: Algorithms on sites like YouTube often push people towards extreme, misleading content. Overhauling these content recommendation systems could go a long way to curbing misinformation.
CONFIANÇA: Algoritmos em sites como o YouTube com frequência levam pessoas em direção a conteúdo enganoso e extremista. A reformulação desses sistemas de recomendação de conteúdo pode ajudar bastante a restringir a desinformação.


;SAFETY: Experts have raised the alarm that AI could increase security risks and cyber crime. Platform developers will need to create stronger measures to protect our data and personal security.
SEGURANÇA: Especialistas alertaram que a inteligência artificial poderia aumentar os riscos à segurança e os crimes cibernéticos. Os desenvolvedores de plataformas precisarão criar medidas mais fortes para proteger nossos dados e a segurança pessoal.


;TRANSPARENCY: Automated decisions can have huge personal impact, yet the reasons for decisions are often opaque. We need breakthroughs in explainability and transparency to protect users.
TRANSPARÊNCIA: As decisões automatizadas podem ter um enorme impacto pessoal, mas os motivos das decisões geralmente são opacos. Precisamos de grandes avanços em explicabilidade e transparência para proteger os usuários.


;We are approaching the fight for trustworthy AI in three key ways:
Estamos abordando a luta por inteligência artificial confiável de três principais maneiras:


# Alt text
;Systems Change image
Mudança sistêmica


;We’re shifting the conversation from ‘personal behavior’ to ‘systems change.’
Estamos mudando a conversa de ‘comportamento pessoal’ para ‘mudança sistêmica’.


# WOH stands for World Health Organization
;Fellow Renée DiResta has been key in shifting misinfo conversation from ‘fake news’ to ‘<a>free speech does not equal free reach.</a>’ Companies have responded: Pinterest stopped sharing vaccination search results & Facebook has started promoting WHO info with vaccine posts.
Fellow Renée DiResta has been key in shifting misinfo conversation from ‘fake news’ to ‘<a>free speech does not equal free reach.</a>’ Companies have responded: Pinterest stopped sharing vaccination search results & Facebook has started promoting WHO info with vaccine posts.


# Alt text
;Companies Accountable image
Companies Accountable image


;We’re holding companies accountable & our approach is spreading.
We’re holding companies accountable & our approach is spreading.


;For our <a>YouTube Regrets</a> campaign we collected YouTube users’ stories about the platform’s recommendation engine leading them down bizarre and sometimes dangerous pathways. This work was catalyzed by our own research on <a>trustworthy AI</a>; stories in the media; and by YouTube engineers who have <a>spoken out</a>.
Para nossa campanha <a>Arrependimentos no YouTube</a>, coletamos de usuários do YouTube histórias sobre o mecanismo de recomendação da plataforma os levar a caminhos bizarros e às vezes perigosos. Este trabalho foi catalisado por nossa própria pesquisa sobre <a>inteligência artificial confiável</a>, histórias na mídia e por engenheiros do YouTube que <a>se pronunciaram</a>.


# Alt text
;Trustworthy AI innovations image
Inovações em inteligência artificial confiável


;We’re supporting trustworthy AI innovations.
Apoiamos inovações em inteligência artificial confiável.


;Fellow Dave Gehring’s ‘Meridio Project’ seeks to create a viable economic framework to support journalism outside the current surveillance-based ad model. He’s established the interest and documented the needs among publishers, and will now move to build the platform that would deliver services.
Fellow Dave Gehring’s ‘Meridio Project’ seeks to create a viable economic framework to support journalism outside the current surveillance-based ad model. He’s established the interest and documented the needs among publishers, and will now move to build the platform that would deliver services.


