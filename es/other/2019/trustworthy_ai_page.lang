## NOTE: Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/


# Content of the Trustworthy AI page: https://foundation.mozilla.org/internet-health/trustworthy-artificial-intelligence/
;A majority of Mozilla’s movement building work is focused on developing trustworthy AI.
Gran parte de la labor de movilización de Mozilla se centra en desarrollar una IA confiable.


;We need to move towards a world of AI that is helpful — rather than harmful — to human beings. For us, this means two things: human agency is a core part of how AI is built and integrated and corporate accountability is real and enforced.
Necesitamos avanzar hacia un mundo donde la IA beneficie, más que perjudique, a los seres humanos. Para nosotros esto significa que 1) la acción humana forme parte integral de la manera de construir e incorporar la IA, y 2) la responsabilidad corporativa sea real y se haga cumplir.


;The need for this work is urgent. Daily, concerning stories hit the news about the effects of AI, big data and targeted marketing; and time and again we read that the public is losing trust in big tech yet doesn’t have any alternatives.
Esta es una labor que se necesita con urgencia. Cada día vemos noticias preocupantes sobre los efectos de la IA, los macrodatos y la mercadotecnia dirigida, y leemos relatos de que los ciudadanos están perdiendo la confianza en las grandes tecnológicas y no hay nada que puedan hacer al respecto.


;Many of us do not yet fully understand how AI regularly touches our lives and feel powerless in the face of these systems. At Mozilla we’re dedicated to making sure that we all understand that we can and must have a say in when machines are used to make important decisions – and shape how those decisions are made.
Muchos de nosotros, aunque no del todo conscientes de la influencia continua de la IA en nuestras vidas, nos sentimos impotentes ante dichos sistemas. Mozilla se dedica a asegurar que todos entendamos que podemos y debemos tener voz y voto en cuándo utilizar máquinas para tomar decisiones importantes y cómo se deben tomar.


;The stakes include:
Entre otros, los aspectos de nuestra labor incluyen:


;PRIVACY: Our personal data powers everything from traffic maps to targeted advertising. Trustworthy AI should let people decide how their data is used and what decisions are made with it.
PRIVACIDAD: Nuestros datos personales alimentan infinidad de cosas, desde mapas del transito hasta la publicidad dirigida. La IA debería permitir que la gente decida cómo se usan sus datos y qué decisiones se toman con ellos.


;FAIRNESS: We’ve seen time and again that historical bias can show up in automated decision making. To effectively address discrimination, we need to look closely at the goals and data that fuel our AI.
EQUIDAD: Hemos podido constatar repetidamente que el sesgo histórico puede presentarse en la toma de decisiones automatizada. Para resolver de fondo esta discriminación, necesitamos analizar detenidamente los propósitos y datos que alimentan nuestra IA.


;TRUST: Algorithms on sites like YouTube often push people towards extreme, misleading content. Overhauling these content recommendation systems could go a long way to curbing misinformation.
CONFIANZA: Los algoritmos en sitios como YouTube suelen conducirnos a contenido extremo y engañoso. La transformación radical de estos sistemas de recomendación de contenido podría hacer mucho en el combate a la desinformación


;SAFETY: Experts have raised the alarm that AI could increase security risks and cyber crime. Platform developers will need to create stronger measures to protect our data and personal security.
SEGURIDAD: Distintos expertos han advertido que la IA podría aumentar los riesgos de seguridad y la delincuencia cibernética. Los desarrolladores de plataformas necesitan tomar medidas más estrictas para proteger nuestros datos y seguridad personal.


;TRANSPARENCY: Automated decisions can have huge personal impact, yet the reasons for decisions are often opaque. We need breakthroughs in explainability and transparency to protect users.
TRANSPARENCIA: Las decisiones automatizadas pueden repercutir enormemente en nosotros, y, no obstante, los motivos de esas decisiones pocas veces son transparentes. Necesitamos lograr avances en la explicabilidad y transparencia para proteger a los usuarios.


;We are approaching the fight for trustworthy AI in three key ways:
Abordamos la lucha por una IA confiable de tres maneras fundamentales:


# Alt text
;Systems Change image
La imagen de que los sistemas se modifiquen


;We’re shifting the conversation from ‘personal behavior’ to ‘systems change.’
Estamos cambiando el punto focal del "comportamiento personal" a la "modificación de los sistemas".


# WOH stands for World Health Organization
;Fellow Renée DiResta has been key in shifting misinfo conversation from ‘fake news’ to ‘<a>free speech does not equal free reach.</a>’ Companies have responded: Pinterest stopped sharing vaccination search results & Facebook has started promoting WHO info with vaccine posts.
Nuestra colega Renée DiResta ha sido pieza fundamental para que el centro de la conversación ya no gire en torno a las "noticias falsa" sino a "<a>la libertad de expresión no equivale a libertad de intrusión.</a>" Las compañías han reaccionado: Pinterest dejó de compartir datos sobre búsquedas de vacunas y Facebook ha empezado a promover información de la OMS acerca de publicaciones sobre vacunas.


# Alt text
;Companies Accountable image
La imagen de que las compañías rindan cuentas


;We’re holding companies accountable & our approach is spreading.
Estamos haciendo que las compañías se responsabilicen y otros nos están imitando.


;For our <a>YouTube Regrets</a> campaign we collected YouTube users’ stories about the platform’s recommendation engine leading them down bizarre and sometimes dangerous pathways. This work was catalyzed by our own research on <a>trustworthy AI</a>; stories in the media; and by YouTube engineers who have <a>spoken out</a>.
Para nuestra campaña de <a>Contrariedades en YouTube</a>, recopilamos historias de usuarios de YouTube sobre cómo el motor de recomendaciones de esta plataforma los condujo por rumbos extraños y a veces peligrosos. Este trabajo se derivó de nuestra propia investigación sobre historias de <a>IA confiable</a> en los medios y las <a>denuncias</a> de algunos ingenieros de YouTube.


# Alt text
;Trustworthy AI innovations image
La imagen de que las innovaciones de IA sean confiables


;We’re supporting trustworthy AI innovations.
Estamos a favor de las innovaciones de IA confiables.


;Fellow Dave Gehring’s ‘Meridio Project’ seeks to create a viable economic framework to support journalism outside the current surveillance-based ad model. He’s established the interest and documented the needs among publishers, and will now move to build the platform that would deliver services.
El Proyecto Meridio de nuestro colega Dave Gehring tiene por objetivo crear un marco económico viable para sustentar el periodismo fuera del actual modelo de anuncios basado en vigilancia. Dave ha despertado el interés y documentado la necesidad de las casas editoriales, y ahora va a construir la plataforma que proporcione los servicios.


